# Experimental configuration
seeds = [42, 123, 456, 789, 1011]  # 5 different random seeds
configurations = 7  # model variants
metrics = ['BLEU', 'TER', 'chrF++', 'UAS', 'LAS', 'Macro-F1', 'OTNA']

# Results structure: seeds × configurations × metrics
results = np.zeros((5, 7, 7))
# Proposed adapter architecture for comparison
class ToxicityAdapter(nn.Module):
    def __init__(self, hidden_size, adapter_size):
        super().__init__()
        self.down_proj = nn.Linear(hidden_size, adapter_size)
        self.up_proj = nn.Linear(adapter_size, hidden_size)
        self.activation = nn.ReLU()
        
    def forward(self, hidden_states):
        # Add adapter after FFN in each transformer layer
        down = self.activation(self.down_proj(hidden_states))
        up = self.up_proj(down)
        return hidden_states + up

# Training: Freeze base model, only train adapters + classification head

class ContextAwareNeutralizer(nn.Module):
    def __init__(self, hidden_size, vocab_size):
        super().__init__()
        # Semantic Similarity Scorer
        self.semantic_scorer = nn.Linear(hidden_size * 2, 1)
        
        # Fluency Preserver (Small LM Head)
        self.fluency_head = nn.Linear(hidden_size, vocab_size)
        
        # Intent Classifier (for sarcasm, hyperbole, etc.)
        self.intent_classifier = nn.Linear(hidden_size, 5)  # literal, sarcasm, hyperbole, threat, praise
        
    def forward(self, offensive_token_rep, context_representation, candidate_synonyms):
        # Step 1: Intent Analysis
        intent_logits = self.intent_classifier(offensive_token_rep)
        intent = torch.argmax(intent_logits, dim=-1)
        
        # Step 2: Context-Aware Synonym Scoring
        neutralized_candidates = []
        for synonym in candidate_synonyms:
            # Get embedding for candidate synonym
            synonym_rep = self.embedding(synonym)
            
            # Calculate semantic fidelity
            context_similarity = self.semantic_scorer(
                torch.cat([context_representation, synonym_rep], dim=-1)
            )
            
            # Calculate fluency score
            fluency_score = self.fluency_head(synonym_rep)
            
            # Combine scores (semantic + fluency + intent preservation)
            combined_score = 0.6 * context_similarity + 0.3 * fluency_score + 0.1 * intent_preservation_score
            
            neutralized_candidates.append((synonym, combined_score))
        
        return sorted(neutralized_candidates, key=lambda x: x[1], reverse=True)[0]

def get_context_representation(encoder_output, offensive_token_positions):
    """Get rich context representation around offensive content"""
    
    # 1. Local context (immediate surrounding words)
    local_context = encoder_output[offensive_token_positions[0]-3:offensive_token_positions[-1]+3]
    
    # 2. Discourse context (sentence-level representation)
    discourse_context = mean_pool(encoder_output)
    
    # 3. Dependency context (syntactically related words)
    dependency_neighbors = get_dependency_neighbors(offensive_token_positions)
    dep_context = encoder_output[dependency_neighbors]
    
    return torch.cat([local_context, discourse_context, dep_context])

